# Model Compression (Feb 28, 2022)
we provided an overview of speech recognition models and model compression techniques in this session.

## Demo for Knowledge Distillation

We used `audio_and_transcription_demo.ipynb` to demo original and distilled models' performances when transcribing speech audio.

## Installation

Please follow [here](https://github.com/georgian-io/Knowledge-Distillation-Toolkit/tree/main/examples/wav2vec2_compression_demo) to install all necessary packages for this notebook.
